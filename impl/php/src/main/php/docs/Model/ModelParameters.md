# # ModelParameters

## Properties

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**max_tokens** | **int** | The maximum number of tokens to be returned by the model. | [optional]
**temperature** | **float** | The sampling temperature to use. Higher values make the output more random, while lower values make it more focused and deterministic. | [optional]
**frequency_penalty** | **float** | Higher values penalize new tokens based on their existing frequency in the text so far, decreasing the model&#39;s likelihood to repeat the same line verbatim. | [optional]
**presence_penalty** | **float** | Higher values penalize new tokens based on whether they appear in the text so far, increasing the model&#39;s likelihood to talk about new topics. | [optional]

[[Back to Model list]](../../README.md#models) [[Back to API list]](../../README.md#endpoints) [[Back to README]](../../README.md)
